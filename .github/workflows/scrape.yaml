name: Scrape

on:
  push:
    branches:
      - main
    paths:
      - .github/workflows/scrape.yml
      - postprocess.js
  pull_request:
    branches:
      - main
    paths:
      - .github/workflows/scrape.yml
      - postprocess.js
  workflow_dispatch: 
    inputs:
      branch:
        required: false
        default: 'main'
  schedule:
    # Run this workflow at 12:00 p.m. (noon) every day
    - cron: '0 12 * * *'

jobs:
  scheduled:
    # Run on a fresh virtual machine hosted by GitHub
    runs-on: ubuntu-latest
    steps:
      # The first step is to check out the repository so it can read the files inside of it and do other operations
      - name: Check out repo
        id: checkout-code
        uses: actions/checkout@v4

      # The second step installs Deno, which is a new Javascript runtime that improves on Node, used for postprocessing later
      - name: Setup deno
        id: setup-deno
        uses: denoland/setup-deno@v2
        with:
          deno-version: v1.x
          
      # The third step is a 'Flat Action' step--- we fetch the data in the 'http_url' and save it as 'downloaded_filename'
      - name: Fetch data 
        id: fetch-data
        uses: githubocto/flat@v3
        with:
          # The endpoint from which data is to be fetched at 12:00 p.m. (noon) every day
          http_url: https://api.coindesk.com/v2/bpi/currentprice.json
          # The http_url is saved and renamed in the repository as 'btc-price.json'
          downloaded_filename: btc-price.json
          # A postprocessing javascript 
          postprocess: postprocess.js 
